import os
import time
import re
import sqlite3
import hashlib
from datetime import datetime, timezone

import feedparser
import requests

# =========================
# CONFIG
# =========================
TOKEN = os.environ.get("BOT_TOKEN")
if not TOKEN:
    raise Exception("BOT_TOKEN missing in environment variables (BOT_TOKEN)")

# Ù‚Ù†Ø§Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… (ÙŠÙˆØ²Ø±Ù†ÙŠÙ… Ø§Ù„Ù‚Ù†Ø§Ø© Ø¨Ø¯ÙˆÙ† @ Ø£Ùˆ Ù…Ø¹ @ Ø§Ù„Ø§Ø«Ù†ÙŠÙ† ÙŠÙ…Ø´ÙˆÙ†)
CHANNEL = "@news_forexq"
SIGNATURE = "\n\nâ€” @news_forexq"

# Ù…ØµØ§Ø¯Ø± Ø¹Ø±Ø¨ÙŠØ© (RSS)
FEEDS = [
    "https://ar.fxstreet.com/rss/news",                  # FXStreet Arabic
    "https://www.arabictrader.com/rss/news",             # ArabicTrader
    "https://arab.dailyforex.com/rss/arab/forexnews.xml" # DailyForex Arabic
]

POLL_SECONDS = 25
MAX_PER_FEED = 25
SUMMARY_MAX_CHARS = 360

# ÙƒÙ„Ù…Ø§Øª "Ø¹Ø§Ø¬Ù„/Ø°Ù‡Ø¨ÙŠ" (Ø¹Ø±Ø¨ÙŠ + Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ù„Ùˆ Ø·Ù„Ø¹ Ø¶Ù…Ù† Ø§Ù„Ù†Øµ)
URGENT_KEYWORDS = [
    "Ø¹Ø§Ø¬Ù„", "Ø®Ø¨Ø± Ø¹Ø§Ø¬Ù„", "ØªÙ†Ø¨ÙŠÙ‡", "ØªØ­Ø°ÙŠØ±",
    "Ø§Ù„ÙÙŠØ¯Ø±Ø§Ù„ÙŠ", "Ø¨Ø§ÙˆÙ„", "ÙØ§ÙŠØ¯Ø©", "Ù‚Ø±Ø§Ø± Ø§Ù„ÙØ§Ø¦Ø¯Ø©",
    "Ø§Ù„ØªØ¶Ø®Ù…", "cpi", "nfp", "Ø§Ù„ÙˆØ¸Ø§Ø¦Ù",
    "Ø°Ù‡Ø¨", "xau", "Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±", "usd",
    "eurusd", "gbpusd", "usdjpy",
    "Ø¨Ø±Ù†Øª", "wti", "Ù†ÙØ·", "oil",
    "ØªØ¯Ø®Ù„", "intervention"
]

# ØªØµÙ†ÙŠÙ "Ù‚ÙˆØ© Ø§Ù„Ø®Ø¨Ø±" (ØªÙ‚Ø±ÙŠØ¨ÙŠ Ø­Ø³Ø¨ ÙƒÙ„Ù…Ø§Øª)
IMPACT_HIGH = ["Ù‚Ø±Ø§Ø±", "Ø§Ù„ÙØ§Ø¦Ø¯Ø©", "Ø§Ù„ÙÙŠØ¯Ø±Ø§Ù„ÙŠ", "Ø¨Ø§ÙˆÙ„", "cpi", "nfp", "ØªØ¶Ø®Ù…", "jobs", "ØªØ¯Ø®Ù„", "intervention"]
IMPACT_MED  = ["ØªÙˆÙ‚Ø¹Ø§Øª", "Ø¨ÙŠØ§Ù†Ø§Øª", "Ù…Ø¤Ø´Ø±", "ØªØµØ±ÙŠØ­Ø§Øª", "Ù…Ø­Ø¶Ø±", "gdp", "pmi", "Ù…Ø¨ÙŠØ¹Ø§Øª", "Ø¨Ø·Ø§Ù„Ø©"]
IMPACT_LOW  = ["ØªØ­Ù„ÙŠÙ„", "Ù†Ø¸Ø±Ø©", "Ù…Ù„Ø®Øµ", "ØªØ¹Ù„ÙŠÙ‚", "Ø§ÙØªØªØ§Ø­", "Ø¥ØºÙ„Ø§Ù‚", "Ø§Ø³ØªÙ‚Ø±Ø§Ø±"]

# ØªØµÙ†ÙŠÙ "Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙˆÙ‚" (ØªÙ‚Ø±ÙŠØ¨ÙŠ)
POS_WORDS = ["Ø§Ø±ØªÙØ§Ø¹", "ØµØ¹ÙˆØ¯", "Ù…ÙƒØ§Ø³Ø¨", "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ", "ÙŠØªØ­Ø³Ù†", "Ù‚ÙˆÙŠ", "Ø§Ù†ØªØ¹Ø§Ø´", "ÙŠØ±ØªÙØ¹", "ÙŠØ²ÙŠØ¯"]
NEG_WORDS = ["Ù‡Ø¨ÙˆØ·", "Ø§Ù†Ø®ÙØ§Ø¶", "Ø®Ø³Ø§Ø¦Ø±", "Ø³Ù„Ø¨ÙŠ", "ÙŠØªØ±Ø§Ø¬Ø¹", "Ø¶Ø¹ÙŠÙ", "ØªØ±Ø§Ø¬Ø¹", "ÙŠÙ†Ø®ÙØ¶", "ÙŠÙ‡Ø¨Ø·"]

# =========================
# DATABASE (dedup)
# =========================
DB_FILE = "posted.db"

def init_db() -> None:
    conn = sqlite3.connect(DB_FILE)
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS posted (
            id TEXT PRIMARY KEY,
            created_at TEXT
        )
    """)
    conn.commit()
    conn.close()

def already_posted(item_id: str) -> bool:
    conn = sqlite3.connect(DB_FILE)
    cur = conn.cursor()
    cur.execute("SELECT 1 FROM posted WHERE id=?", (item_id,))
    row = cur.fetchone()
    conn.close()
    return row is not None

def mark_posted(item_id: str) -> None:
    conn = sqlite3.connect(DB_FILE)
    cur = conn.cursor()
    cur.execute(
        "INSERT OR IGNORE INTO posted (id, created_at) VALUES (?, ?)",
        (item_id, datetime.now(timezone.utc).isoformat())
    )
    conn.commit()
    conn.close()

# =========================
# HELPERS
# =========================
URL_RE = re.compile(r"(https?://\S+)", re.IGNORECASE)

def clean(text: str) -> str:
    if not text:
        return ""
    return " ".join(text.replace("\n", " ").split()).strip()

def remove_urls(text: str) -> str:
    """ÙŠØ´ÙŠÙ„ Ø£ÙŠ Ø±Ø§Ø¨Ø· Ù…Ù† Ø§Ù„Ù†Øµ Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹."""
    if not text:
        return ""
    text = URL_RE.sub("", text)  # remove urls
    # remove any leftover lines containing 'http'
    lines = [ln for ln in text.splitlines() if "http" not in ln.lower()]
    return " ".join(" ".join(lines).split()).strip()

def make_hash_id(title: str, published: str, src: str) -> str:
    raw = (clean(title) + "||" + clean(published) + "||" + clean(src)).encode("utf-8")
    return hashlib.sha256(raw).hexdigest()

def source_label(feed_url: str) -> str:
    u = feed_url.lower()
    if "fxstreet" in u:
        return "FXStreet"
    if "arabictrader" in u:
        return "Ø§Ù„Ù…ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø¹Ø±Ø¨ÙŠ"
    if "dailyforex" in u:
        return "DailyForex"
    return "Ø§Ù„Ù…ØµØ¯Ø±"

def is_urgent(title: str, summary: str) -> bool:
    combined = (title + " " + summary).lower()
    return any(k.lower() in combined for k in URGENT_KEYWORDS)

def impact_level(title: str, summary: str) -> str:
    t = (title + " " + summary).lower()
    if any(k.lower() in t for k in IMPACT_HIGH):
        return "Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹"
    if any(k.lower() in t for k in IMPACT_MED):
        return "Ù…ØªÙˆØ³Ø·"
    if any(k.lower() in t for k in IMPACT_LOW):
        return "Ù…Ù†Ø®ÙØ¶"
    return "Ù…ØªÙˆØ³Ø·"

def market_sentiment(title: str, summary: str) -> str:
    t = (title + " " + summary).lower()
    pos = sum(1 for w in POS_WORDS if w in t)
    neg = sum(1 for w in NEG_WORDS if w in t)
    if pos > neg and pos >= 1:
        return "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ"
    if neg > pos and neg >= 1:
        return "Ø³Ù„Ø¨ÙŠ"
    return "Ù…Ø­Ø§ÙŠØ¯"

def affected_assets(title: str, summary: str) -> str:
    t = (title + " " + summary).lower()
    assets = []
    # Ø¹Ù…Ù„Ø§Øª/Ø£Ø²ÙˆØ§Ø¬ Ø´Ø§Ø¦Ø¹Ø©
    for key, name in [
        ("eurusd", "EUR/USD"),
        ("gbpusd", "GBP/USD"),
        ("usdjpy", "USD/JPY"),
        ("usdchf", "USD/CHF"),
        ("audusd", "AUD/USD"),
        ("usdcad", "USD/CAD"),
        ("nzdusd", "NZD/USD"),
        ("xau", "Ø§Ù„Ø°Ù‡Ø¨"),
        ("gold", "Ø§Ù„Ø°Ù‡Ø¨"),
        ("oil", "Ø§Ù„Ù†ÙØ·"),
        ("brent", "Ø§Ù„Ù†ÙØ· (Ø¨Ø±Ù†Øª)"),
        ("wti", "Ø§Ù„Ù†ÙØ· (WTI)"),
        ("usd", "Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±"),
        ("eur", "Ø§Ù„ÙŠÙˆØ±Ùˆ"),
        ("gbp", "Ø§Ù„Ø¥Ø³ØªØ±Ù„ÙŠÙ†ÙŠ"),
        ("jpy", "Ø§Ù„ÙŠÙ†"),
        ("chf", "Ø§Ù„ÙØ±Ù†Ùƒ"),
        ("aud", "Ø§Ù„Ø£Ø³ØªØ±Ø§Ù„ÙŠ"),
        ("cad", "Ø§Ù„ÙƒÙ†Ø¯ÙŠ"),
        ("nzd", "Ø§Ù„Ù†ÙŠÙˆØ²ÙŠÙ„Ù†Ø¯ÙŠ"),
    ]:
        if key in t and name not in assets:
            assets.append(name)

    if not assets:
        return "â€”"
    # Ù„Ø§ Ù†Ø·ÙˆÙ‘Ù„
    return "ØŒ ".join(assets[:4]) + ("â€¦" if len(assets) > 4 else "")

def short_summary(summary: str) -> str:
    s = clean(summary)
    s = remove_urls(s)  # âœ… Ø£Ù‡Ù… Ø³Ø·Ø±: Ø´ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„ÙˆØµÙ Ù†ÙØ³Ù‡
    if not s:
        return ""
    return s[:SUMMARY_MAX_CHARS] + ("..." if len(s) > SUMMARY_MAX_CHARS else "")

def tg_send_message(html_text: str) -> None:
    """Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… (HTML) Ø¨Ø¯ÙˆÙ† Ø±ÙˆØ§Ø¨Ø· ÙˆÙ…Ø¹ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø¹Ø§ÙŠÙ†Ø©."""
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    payload = {
        "chat_id": CHANNEL,
        "text": html_text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    r = requests.post(url, data=payload, timeout=20)
    if r.status_code != 200:
        raise Exception(f"Telegram API error: {r.status_code} {r.text}")

def build_news_message(title: str, summary: str, src: str, published: str) -> str:
    title = remove_urls(clean(title))  # âœ… Ø­ØªÙ‰ Ù„Ùˆ Ø¹Ù†ÙˆØ§Ù†Ù‡ ÙÙŠÙ‡ Ø±Ø§Ø¨Ø·
    summary = short_summary(summary)

    imp = impact_level(title, summary)
    mood = market_sentiment(title, summary)
    assets = affected_assets(title, summary)

    # Ø´Ø§Ø±Ø© "ØªÙ†Ø¨ÙŠÙ‡ Ø°Ù‡Ø¨ÙŠ" Ø¥Ø°Ø§ Ø¹Ø§Ø¬Ù„
    urgent = is_urgent(title, summary)
    header = "ğŸŸ¨ <b>ØªØ­Ø°ÙŠØ± Ø°Ù‡Ø¨ÙŠ</b>\n" if urgent else "ğŸ“° "

    msg = f"{header}<b>{title}</b>\n\n"
    if summary:
        msg += f"{summary}\n\n"

    msg += "Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€\n"
    msg += f"ğŸ“Š <b>Ù‚ÙˆØ© Ø§Ù„Ø®Ø¨Ø±:</b> {imp}\n"
    msg += f"ğŸ§  <b>Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙˆÙ‚:</b> {mood}\n"
    msg += f"ğŸ“Œ <b>Ø§Ù„Ø£Ù…ÙˆØ§Ù„ Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©:</b> {assets}\n"
    msg += f"ğŸ•’ <b>Ø§Ù„ÙˆÙ‚Øª:</b> {published}\n"
    msg += f"ğŸ”— <b>Ø§Ù„Ù…ØµØ¯Ø±:</b> {src}\n"
    msg += "Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€"
    msg += SIGNATURE

    # âœ… Ø¶Ù…Ø§Ù† Ù†Ù‡Ø§Ø¦ÙŠ: Ù„Ø§ Ø±ÙˆØ§Ø¨Ø· Ø£Ø¨Ø¯Ø§Ù‹
    msg = remove_urls(msg)
    return msg

def format_published(entry) -> str:
    # Ù†Ø­Ø§ÙˆÙ„ Ù†Ø·Ù„Ø¹ ÙˆÙ‚Øª Ø¬Ù…ÙŠÙ„ØŒ ÙˆØ¥Ø°Ø§ Ù…Ø§ ØªÙˆÙØ± Ù†Ø³ØªØ®Ø¯Ù… UTC Ø§Ù„Ø­Ø§Ù„ÙŠ
    dt = None
    if hasattr(entry, "published_parsed") and entry.published_parsed:
        try:
            dt = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
        except Exception:
            dt = None

    if not dt:
        dt = datetime.now(timezone.utc)

    # ØµÙŠØºØ© ÙˆØ§Ø¶Ø­Ø©
    return dt.strftime("%Y-%m-%d %H:%M UTC")

# =========================
# MAIN LOOP
# =========================
def main() -> None:
    init_db()
    print("Bot Running...")

    while True:
        try:
            for feed_url in FEEDS:
                feed = feedparser.parse(feed_url)
                src = source_label(feed_url)

                for entry in feed.entries[:MAX_PER_FEED]:
                    title = entry.get("title", "")
                    link = entry.get("link", "")  # Ù…Ø§ Ø±Ø§Ø­ Ù†Ø³ØªØ®Ø¯Ù…Ù‡ (Ø·Ù„Ø¨Ùƒ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø·)
                    summary = entry.get("summary") or entry.get("description") or ""
                    published = format_published(entry)

                    # Dedup by id or stable hash
                    item_id = entry.get("id") or make_hash_id(title, published, src)

                    if already_posted(item_id):
                        continue

                    msg = build_news_message(title=title, summary=summary, src=src, published=published)

                    # Ø¥Ø±Ø³Ø§Ù„
                    tg_send_message(msg)

                    # ØªØ¹Ù„ÙŠÙ… Ø£Ù†Ù‡ Ø§Ù†Ø±Ø³Ù„
                    mark_posted(item_id)

                    time.sleep(1.0)

            time.sleep(POLL_SECONDS)

        except Exception as ex:
            print("Error:", ex)
            time.sleep(10)

if __name__ == "__main__":
    main()